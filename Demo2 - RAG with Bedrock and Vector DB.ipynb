{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aecbeb0f-33e7-4316-8b38-04a958bd3cd7",
   "metadata": {},
   "source": [
    "# Part 1 - Bedrock Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2535265e-9f31-4961-8c6a-7d6ee5000066",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Amazon Bedrock is an internal technology platform developed by Amazon to run and operate many of their services and products. Some key things about Bedrock:\n",
      "\n",
      "- It provides foundational services like compute, storage, database, networking that power many Amazon products and services. Bedrock acts as a common infrastructure layer.\n",
      "\n",
      "- It enables Amazon to rapidly launch and scale new products and services by building on top of Bedrock rather than having to develop everything from scratch. \n",
      "\n",
      "- It incorporates technologies like containers and microservices to allow for modularity and frequent updates.\n",
      "\n",
      "- Bedrock is used across many Amazon businesses including Amazon.com, Amazon Web Services, Alexa, Prime Video, etc.\n",
      "\n",
      "- It aims to increase developer productivity and reduce time-to-market for new products by providing common tools and services out of the box.\n",
      "\n",
      "- Bedrock is a proprietary technology stack developed internally by Amazon. The details are not public but it is seen as one of Amazon's key competitive advantages.\n",
      "\n",
      "So in summary, Bedrock is the foundational technology platform underlying many Amazon products and services, allowing them to scale rapidly by providing common infrastructure and services. It is central to Amazon's ability to operate and innovate at such large scale.\n"
     ]
    }
   ],
   "source": [
    "import boto3, json, os\n",
    "bedrock = boto3.client(service_name='bedrock-runtime')\n",
    "body = json.dumps({\n",
    " \"prompt\": \"\\n\\nHuman: What is Amazon Bedrock? \\n\\nAssistant:\",\n",
    " \"max_tokens_to_sample\": 300,\n",
    " \"temperature\": 0.1,\n",
    " \"top_p\": 0.9,\n",
    "})\n",
    "modelId = 'anthropic.claude-v2'\n",
    "accept = 'application/json'\n",
    "contentType = 'application/json'\n",
    "\n",
    "response = bedrock.invoke_model(body=body, modelId=modelId, accept=accept, contentType=contentType)\n",
    "\n",
    "response_body = json.loads(response.get('body').read())\n",
    "# text\n",
    "print(response_body.get('completion'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9c0601e8-c056-4262-93d7-176d9dada5c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bedrock_client = boto3.client(service_name='bedrock-runtime')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e10e8a9-dd61-4ebb-89ae-fb45365066d7",
   "metadata": {},
   "source": [
    "# Part 2 - Creating embedding and storing in a vector database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "41df8716-0144-499c-8226-2161b747cb4f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We will be using the Titan Embeddings Model to generate our Embeddings.\n",
    "from langchain.embeddings import BedrockEmbeddings\n",
    "from langchain.llms.bedrock import Bedrock\n",
    "\n",
    "# - create the Anthropic Model\n",
    "llm = Bedrock(\n",
    "    model_id=\"anthropic.claude-v2\", \n",
    "    client=bedrock_client, \n",
    "    model_kwargs={\"max_tokens_to_sample\": 200}\n",
    ")\n",
    "bedrock_embeddings = BedrockEmbeddings(model_id=\"amazon.titan-embed-text-v1\", client=bedrock_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3792d7c3-e4b7-4dfe-b5d8-85e1f6278304",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from urllib.request import urlretrieve\n",
    "\n",
    "os.makedirs(\"data\", exist_ok=True)\n",
    "files = [\n",
    "    \"https://docs.aws.amazon.com/bedrock/latest/userguide/bedrock-ug.pdf\",\n",
    "    \"https://docs.aws.amazon.com/bedrock/latest/APIReference/bedrock-api.pdf\",\n",
    "]\n",
    "for url in files:\n",
    "    file_path = os.path.join(\"data\", url.rpartition(\"/\")[2])\n",
    "    urlretrieve(url, file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "83d1610e-1494-4a1c-9e1f-b1078b2f5264",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from langchain.text_splitter import CharacterTextSplitter, RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import PyPDFLoader, PyPDFDirectoryLoader\n",
    "\n",
    "loader = PyPDFDirectoryLoader(\"./data/\")\n",
    "\n",
    "documents = loader.load()\n",
    "# - in our testing Character split works better with this PDF data set\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    # Set a really small chunk size, just to show.\n",
    "    chunk_size = 1000,\n",
    "    chunk_overlap  = 0,\n",
    ")\n",
    "docs = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c044e860-dd3a-4eef-9d40-8d37c19df196",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from langchain.text_splitter import CharacterTextSplitter, RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import PyPDFLoader, PyPDFDirectoryLoader\n",
    "\n",
    "loader = PyPDFDirectoryLoader(\"./data/\")\n",
    "\n",
    "documents = loader.load()\n",
    "# - in our testing Character split works better with this PDF data set\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    # Set a really small chunk size, just to show.\n",
    "    chunk_size = 1000,\n",
    "    chunk_overlap  = 0,\n",
    ")\n",
    "docs = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1092c97f-042d-40cc-b500-e6aa8574cc0f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content=\"Amazon Bedrock API ReferenceAmazon Bedrock: API Reference\\nCopyright © 2023 Amazon Web Services, Inc. and/or its aﬃliates. All rights reserved.\\nAmazon's trademarks and trade dress may not be used in connection with any product or service that is not \\nAmazon's, in any manner that is likely to cause confusion among customers, or in any manner that disparages or \\ndiscredits Amazon. All other trademarks not owned by Amazon are the property of their respective owners, who may \\nor may not be aﬃliated with, connected to, or sponsored by Amazon.\", metadata={'source': 'data/bedrock-api.pdf', 'page': 1})"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "03ab5514-4890-4819-8bc6-11eb363f18d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pinecone, time\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(\"keys.env\") # Load variables from .env file\n",
    "\n",
    "\n",
    "# add index name from pinecone.io\n",
    "index_name = ''\n",
    "# add Pinecone API key from app.pinecone.io\n",
    "api_key = os.environ.get(\"PINECONE_API_KEY\")\n",
    "# set Pinecone environment - find next to API key in console\n",
    "env = os.environ.get(\"PINECONE_ENVIRONMENT\")\n",
    "\n",
    "#pinecone.init(api_key=api_key, environment=env)\n",
    "\n",
    "# Initialize Pinecone\n",
    "pinecone.init(api_key=api_key, environment=env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c81494ce-dc8f-4260-b330-28879bcd8664",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample embedding of a document chunk:  [-6.1392784e-06  2.2558594e-01  7.6953125e-01 ...  2.2363281e-01\n",
      " -8.2421875e-01 -1.3671875e-01]\n",
      "Size of the embedding:  (1536,)\n"
     ]
    }
   ],
   "source": [
    "sample_embedding = np.array(bedrock_embeddings.embed_query(docs[1].page_content))\n",
    "print(\"Sample embedding of a document chunk: \", sample_embedding)\n",
    "print(\"Size of the embedding: \", sample_embedding.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c375a873-30e4-4b74-8b98-b775ef4d212e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 1536,\n",
       " 'index_fullness': 0.0,\n",
       " 'namespaces': {},\n",
       " 'total_vector_count': 0}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# used documentation from https://python.langchain.com/docs/integrations/vectorstores/pinecone\n",
    "index_name = \"demoindex\"\n",
    "index = pinecone.Index(index_name)\n",
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4a66a21a-5010-4201-b1eb-10d5d4290c34",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.12 s, sys: 171 ms, total: 3.29 s\n",
      "Wall time: 1min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from langchain.vectorstores import Pinecone\n",
    "\n",
    "docsearch = Pinecone.from_documents(docs, bedrock_embeddings, index_name=index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c592e992-6545-4506-892b-71baafb74bdf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Pinecone\n",
    "\n",
    "text_field = \"text\"\n",
    "\n",
    "# switch back to normal index for langchain\n",
    "index = pinecone.Index(index_name)\n",
    "\n",
    "vectorstore = Pinecone(index, bedrock_embeddings, text_field)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c0c173-165f-4603-a1d1-ca07c91fb4d0",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Part 3 - Compare using LLM vs LLM + RAG\n",
    "\n",
    "Claude 2 vs LangChain + Claude 2 + Vector Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "36b2e3f0-7862-495a-8c7a-22cbdf8014c9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Amazon Bedrock User GuideTable of Contents\\nWhat is Amazon Bedrock?...................................................................................................................1\\nAccess the Amazon Bedrock models.............................................................................................1\\nFeatures of Amazon Bedrock.......................................................................................................1\\nSupported models in Amazon Bedrock.........................................................................................2\\nSupported Regions.....................................................................................................................3\\nAmazon Bedrock pricing.............................................................................................................3\\nSet up ..............................................................................................................................................4', metadata={'page': 2.0, 'source': 'data/bedrock-ug.pdf'}),\n",
       " Document(page_content='Amazon Bedrock User Guide\\nAccess the Amazon Bedrock models\\nWhat is Amazon Bedrock?\\nAmazon Bedrock is a fully managed service that makes base models from Amazon and third-party model \\nproviders accessible through an API.\\nTopics\\n•Access the Amazon Bedrock models (p. 1)\\n•Features of Amazon Bedrock (p. 1)\\n•Supported models in Amazon Bedrock  (p. 2)\\n•Supported Regions (p. 3)\\n•Amazon Bedrock pricing (p. 3)\\nAccess the Amazon Bedrock models\\nImportant\\nYou must request access to a model before you can use it. If you try to use the model (with the \\nAPI or console) before you have requested access to it, you receive an error message. For more \\ninformation, see Model access (p. 7).\\nFeatures of Amazon Bedrock\\nWith Amazon Bedrock, you can explore the following capabilities:\\n•Text playground – A hands-on text generation application in the AWS Management Console.\\n•Image playground – A hands-on image generation application in the console.', metadata={'page': 7.0, 'source': 'data/bedrock-ug.pdf'}),\n",
       " Document(page_content=\"Amazon Bedrock User GuideAmazon Bedrock: User Guide\\nCopyright © 2023 Amazon Web Services, Inc. and/or its aﬃliates. All rights reserved.\\nAmazon's trademarks and trade dress may not be used in connection with any product or service that is not \\nAmazon's, in any manner that is likely to cause confusion among customers, or in any manner that disparages or \\ndiscredits Amazon. All other trademarks not owned by Amazon are the property of their respective owners, who may \\nor may not be aﬃliated with, connected to, or sponsored by Amazon.\", metadata={'page': 1.0, 'source': 'data/bedrock-ug.pdf'})]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What is Amazon Bedrock?\"\n",
    "\n",
    "vectorstore.similarity_search(query, k=3)  # our search query  # return 3 most relevant docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b9e81aba-df5f-4e15-9de0-58dc9ded7099",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Based on the provided context, Amazon Bedrock is described as \"a fully managed service that makes base models from Amazon and third-party model providers accessible through an API.\"'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# standard prompt based on https://python.langchain.com/docs/use_cases/question_answering/vector_db_qa\n",
    "\n",
    "from langchain.chains import RetrievalQA\n",
    "qa = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=vectorstore.as_retriever())\n",
    "qa.run(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b4a3c1b6-ee8e-4afd-8d47-347f97a09979",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Based on the Amazon Bedrock User Guide provided, Amazon Bedrock is a fully managed service that makes base models from Amazon and third-party model providers accessible through an API. It allows users to explore capabilities like text playground for hands-on text generation, image playground for hands-on image generation, and provides access to models through an API after requesting access.\n"
     ]
    }
   ],
   "source": [
    "# https://github.com/aws-samples/amazon-bedrock-workshop/blob/main/03_QuestionAnswering/02_rag_claude_titan_pinecone.ipynb\n",
    "\n",
    "# csutomizable option\n",
    "\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "\n",
    "Human: Use the following pieces of context to provide a detailed answer to the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Assistant:\"\"\"\n",
    "\n",
    "PROMPT = PromptTemplate(template=prompt_template, input_variables=[\"context\", \"question\"])\n",
    "\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=vectorstore.as_retriever(),\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": PROMPT},\n",
    ")\n",
    "result = qa({\"query\": query})\n",
    "print(result[\"result\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6f75f312-2b02-49e8-9875-08e16930b781",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Here are some of the key features of Amazon Bedrock:\n",
      "\n",
      "- Managed blockchain service - Bedrock is a fully managed blockchain service by AWS that makes it easy to build and scale blockchain networks. Developers don't need to provision hardware or install software.\n",
      "\n",
      "- Support for Ethereum and Hyperledger Fabric - Bedrock supports two of the most popular blockchain frameworks, Ethereum and Hyperledger Fabric. This allows you to build decentralized applications on top of these networks.\n",
      "\n",
      "- High performance and scalability - Bedrock is designed for performance and scalability. It utilizes AWS infrastructure to deliver fast transaction speeds and the ability to scale networks as usage grows.\n",
      "\n",
      "- Secure and compliant - Bedrock provides enterprise-grade security features like encryption, access controls, and integrations with AWS security services. It is compliant with standards like HIPAA, SOC, and PCI. \n",
      "\n",
      "- Integrations with AWS services - Bedrock integrates with various AWS services like Amazon Managed Blockchain, Amazon QLDB, Amazon DynamoDB, Amazon CloudWatch, and more. This makes it easier to build blockchain-based apps on AWS.\n",
      "\n",
      "- Fully managed lifecycle - Bedrock handles provisioning, cluster management, security patching, monitoring, and recovery automatically so developers can focus on application logic.\n",
      "\n",
      "- Open standards support - Bedrock uses open standards like Ethereum and Hyperledger Fabric so you're not locked into proprietary platforms. This provides flexibility and portability.\n"
     ]
    }
   ],
   "source": [
    "#without RAG\n",
    "bedrock = boto3.client(service_name='bedrock-runtime')\n",
    "\n",
    "body = json.dumps({\n",
    " \"prompt\": \"\\n\\nHuman:What are Amazon Bedrock key features?\\n\\nAssistant:\",\n",
    " \"max_tokens_to_sample\": 300,\n",
    " \"temperature\": 0.1,\n",
    " \"top_p\": 0.9,\n",
    "})\n",
    "modelId = 'anthropic.claude-v2'\n",
    "accept = 'application/json'\n",
    "contentType = 'application/json'\n",
    "\n",
    "response = bedrock.invoke_model(body=body, modelId=modelId, accept=accept, contentType=contentType)\n",
    "\n",
    "response_body = json.loads(response.get('body').read())\n",
    "# text\n",
    "print(response_body.get('completion'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9d78547a-0194-4c52-ac1e-f67d4f0b0c07",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Based on the provided context, the Amazon Titan models in Amazon Bedrock are used for natural language processing tasks like text generation. Specifically, the models mentioned are:\n",
      "\n",
      "- Titan Text G1 - Express - A text generation model that is in limited preview release.\n",
      "\n",
      "- Titan Embeddings G1 - Text - A model that generates embeddings from text. Embeddings represent words or sentences as numerical vectors which can be useful for downstream NLP tasks.\n",
      "\n",
      "So in summary, the Amazon Titan models are used for natural language text generation and creating vector representations of text. The context indicates they support features like controlling response length, top-p sampling, and stop sequences when generating text.\n"
     ]
    }
   ],
   "source": [
    "# with RAG\n",
    "\n",
    "query = \"What Amazon Titan model used for?\"\n",
    "vectorstore.similarity_search(query, k=3)  # our search query  # return 3 most relevant docs\n",
    "\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=vectorstore.as_retriever(),\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": PROMPT},\n",
    ")\n",
    "result = qa({\"query\": query})\n",
    "print(result[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07a49b4-9bfc-4087-819a-c0b4656ff12e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-west-2:236514542706:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
